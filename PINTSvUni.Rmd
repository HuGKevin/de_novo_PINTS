---
title: "Univariate-PINTS Comparison"
author: "Kevin Hu"
date: "May 1, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

We've confirmed that PINTS works for ascertainment of genes in heterogeneous disease (with nontrivial power, though of course we could use experiments with bigger sample sizes). At this point, we want to do a direct comparison between PINTS and univariate gene ascertainment (using just a p-value threshold). 

To do so, we'll pick a variety of threshold values, as before (increments of 0.5 log-units). At each threshold, we choose a Bonferroni-corrected threshold and a FDR-controlled threshold (Benjamini-Yekutieli). We then run a number of simulations to determine the sensitivity and specificity when using either PINTS or univariate-detection. Goal is to make two ROC plots for each threshold, one for Bonf, one for FDR. 

A few improvements need to be made to the engine in order for this to be a possibility.

## Steps To Be Taken

The experiment on multiple thresholds took about 8 hours for something like 500 runs. The issue here was mostly that for each iteration of PINTS, I was resimulating data, reconstructing the PPI network, and doing all the setup over and over again. 

So I'm going to edit the script slightly so it runs in the following way:

1. Load in all the data, packages, etc.
2. Create data frame to store results. Columns are things like threshold, case size, # genes, etc. 
3. Simulate case/controls and compute p-values for a particular combination of case size and # genes.
4. Construct the PPI network.
5. For each threshold value, run PINTS to obtain specificity and sensitivity value for that trial.
6. For each threshold value, run univariate-detection to obtain spec and sens for that trial.
7. Repeat 3 to 6 $n$ times, for $n$ total trials in each one. 
8. Output data. 

Rearranging the experiment this way should probably cut runtime down by about 40% or so. 

I can also run the same experiment several times on the clusters simultaneously so they're effectively running in parallel, and then merge the output after the fact. 

One question I have: Our ROC plots will be Sens vs (1-Spec) for each threshold and bonf/FDR combo. Won't it be the case that, at least in the Bonf cases, (1-Spec) will have a tiny range, probably between 0 and 0.05, at the most, given how few genes PINTS will be picking out? Not sure if this is a concern or not.