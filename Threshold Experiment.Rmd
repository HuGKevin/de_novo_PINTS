---
title: "Threshold Experiment"
author: "Kevin Hu"
date: "March 28, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

gene_probs <-
  read.table(
    "mut_data.txt",
    header = TRUE,
    stringsAsFactors = FALSE,
    sep = ","
  )
gene_list <-
  data.frame(
    Ensembl = gene_probs$Ensembl,
    freq = gene_probs$mu_mis + gene_probs$mu_lof,
    stringsAsFactors = FALSE
  )
rm(gene_probs)

control_agg <- read.table("control_summary_10k.txt", sep = "\t", header = TRUE)

# Generate a population with case_number # of cases and control_number # of controls, at a base non-synonymous de novo mutation rate of freq. Returns a nx3 data frame.
Gen_pop <- function(case_number, control_number, freq) {
  ID <- seq(1, case_number + control_number, 1)
  case_mutations <- rpois(case_number, freq)
  control_mutations <- rpois(control_number, freq)
  
  for (i in 1:case_number) {
    while (case_mutations[i] == 0) {
      case_mutations[i] <- rpois(1, freq)
    }
  }
  
  cc <- c(rep(TRUE, case_number), rep(FALSE, control_number))
  
  cohort <- data.frame(ID, cc, c(case_mutations, control_mutations))
  colnames(cohort) <- c("ID", "cc", "mutations")
  
  return(cohort)
}

# Isolates a new data frame from the population data frame that has just the individual ID and the case/control status. Returns an nx2 data frame.
Gen_pop_info <- function(population) {
  pop_info <- data.frame(population$ID, population$cc)
  
  return(pop_info)
}

# Extends the population data frame to have columns for each possible gene that can receive a mutation. Returns an nx(3+g) data frame. 
Initiate_population <- function(population, gene_list) {
  indivs <- rep(0, length(population[[1]]))
  result <- cbind(replicate(length(gene_list), indivs))
  
  result1 <- data.frame(population, result)
  
  names <- c("ID", "case_control", "num_mutations", gene_list)
  colnames(result1) <- names
  
  return(result1)
}

# Given a row from the population, it randomly distributes the mutations amongst the space of genes conditional on case/control status. Returns a row vector.
Dist_mut <-
  function(indiv,
           gene_list,
           gene_freq,
           gene_case_list,
           gene_case_freq) {
    if (indiv[2] == TRUE) {
      mutation <- which(rmultinom(1, 1, gene_case_freq) == 1)
      indiv[as.character(gene_case_list[mutation])] <- 1
      if (indiv[3] > 1) {
        mutation <- rmultinom(1, as.integer(indiv[3]) - 1, gene_freq)
        for (i in which(mutation > 0)) {
          indiv[gene_list[i]] <- mutation[i]
        }
      }
      return(indiv)
      
    }
    else{
      if (indiv[3] == 0) {
        return(indiv)
      }
      else{
        mutation <- rmultinom(1, as.integer(indiv[3]), gene_freq)
        for (i in which(mutation > 0)) {
          indiv[gene_list[i]] <- mutation[i]
        }
        return(indiv)
      }
    }
    
  }

# Function to take in a population data frame and output the same data frame with mutation data. Iterates Dist_mut through apply(). Returns an nx(g+3) data frame. 
Cohort_mut <-
  function(population,
           gene_list,
           gene_freq,
           gene_case_list,
           gene_case_freq) {
    population <- t(apply(population,
                     1,
                     Dist_mut,
                     gene_list,
                     gene_freq,
                     gene_case_list,
                     gene_case_freq))
    #new_pop <- t(new_pop)
    return(population)
  }

# Calculates the probability that a gene is mutated more in cases than controls, under the null that there is no difference between the two. Returns numeric.
Exact_test <- function(gene_mut, case_control) {
  elbat <- table(gene_mut, case_control)
  return(feTestR(elbat[4], elbat[2], elbat[3], elbat[1]))
}

# Function that iterates Exact_test over all the genes. Returns nx2 data frame of p-values. 
Test <- function(population, population_info, num_perms) {
  print("Starting:")
  proc.time()
  gene_id <- colnames(population)[4:length(population[1, ])]
  num <- length(gene_id)
  peoples <- population
  observed <- rep(0, length(gene_id))
  
  permat <- matrix(1, nrow = num, ncol = num_perms + 1)
  
  condition <- as.vector(colSums(population) > 0)
  print("Everything initialized")
  proc.time()
  
  #Make initial observed p-values
  for (i in 1:num) {
    if (condition[i + 3]) {
      permat[i, 1] <-
        Exact_test(peoples[, i + 3], peoples[, 2])
    }
  }
  
  #iterate
  for (i in 1:10) {
    peoples[, 2] <- sample(population_info[, 2])
    for (j in 1:num) {
      if (condition[j + 3]) {
        permat[j, i + 1] <-
          Exact_test(peoples[, j + 3], peoples[, 2])
      }
    }
  }
  
  p.val <- rep(1, num)
  for (i in 1:num) {
    p.val[i] <- sum(permat[i, -1] <= permat[i, 1]) / num_perms
  }
  
  print("final p-vals completed:")
  proc.time()
  
  return(data.frame(gene_id, p.val))
}

# wrapper runs simulations of populations with certain permutations of disease genes against a fixed control background. This is just used for the direct significance calculation. Returns a giant data frame with information on each specific gene, its heterogeneity, the case size, and p-value. We won't really use this. 
#gois is the list of genes of interest with the pLI
#Het is a matrix where each row is the relative proportion of cases it explains, so the length of the row is the number of disease genes there are.
#n is case sample size
#i is number of iterations per parameter set
#controls is aggregate of controls being used
wrapper <- function(gois, Het, n, i, controls) {
  gene_num <- length(Het[1,]) #number of genes that are causal
  long <- t(permutations(length(gois[, 1]), gene_num)) #set of permutations
  
  gene <- rep(as.vector(long), i * length(Het[,1]))
  
  het <- c()
  for (j in 1:length(Het[, 1])) {
    het <- c(het, rep(Het[j,],length(long[1,])))
  }
  het <- rep(het, i)

  num <- n
  
  results <-
  data.frame(gene, het, num, pvals = NA)
  #head(results)
  
  for (j in 1:(length(long[1,]) * length(Het[,1]) * i)) {
    population <- Gen_pop(n, 1, 0.38)[1:n,]
    population <-
      Initiate_population(population, gene_list$Ensembl)
    population <-
      Cohort_mut(population,
                 gene_list$Ensembl,
                 gene_list$freq,
                 gois[results$gene[(gene_num * (j-1) + 1):(gene_num * j)], 1],
                 results$het[(gene_num * (j-1) + 1):(gene_num * j)])
    cases <- colSums(population)
    
    for(q in 1:gene_num){
    results$pvals[gene_num * (j-1) + q] <-
      big_fish(as.character(gois[results$gene[gene_num * (j-1) + q], 1]), cases, controls)
    }
    if(j %% 1000 == 0){
      print(2*j)
    }
  }
  
  return(results)
}

# I'm not sure how this is different from Exact_test, to be honest. Gotta look into this later. 
big_fish <- function(gene, cases, controls) {
  ill_case <- as.integer(cases[gene])
  well_case <- as.integer(cases[2] - cases[gene])
  ill_control <- as.integer(controls[controls[, 1] == gene, 2])
  well_control <- 500000 - ill_control
  
  x <- feTestR(ill_case, well_case, ill_control, well_control)
  return(x)
}

# Generates a heterogeneity matrix for h genes with n different iterations. 
gen_het <- function(h, n){
  dirtframe <- matrix(rep(0, n * h),nrow = n)
  final <- NA
  for(i in 1:n){
    short <- runif(h-1, 0, 100)
    long <- c(short, 0, 100)
    ordered <- sort(long)
    for(j in 1:h){
      final[j] <- ordered[j+1] - ordered[j]
    }
    dirtframe[i,] <- final
  }
  
  return(dirtframe)
}

# Some other packages
library(BioNet)
library(igraph)
library(PINTS)
library(gtools)
library(HighSpeedStats)
library(knitr)
```

## Introduction

We want to better understand the impact of the threshold for our network detection in PINTs on the success of that network detection. As I understand, the profit/cost of each node is the log-difference between the node's significance and the threshold value. Thus, the relative significance of each node is considered in the profit/cost graph. PINTS implements the fast heinz algorithm to find a maximal subnet. I need to read this a bit more. 

The hope is to determine, in light of that, an optimal threshold to use for subnet detection. Ideally, this would allow us to implicate new genes that are at the border of significance and non-significance. 

## Required Files

 * mut_data.txt
 * control_summary_10k.txt, or another source of control mutation counts.
 * genes_of_interest.txt, or another source of possible disease genes.
 * threshold_list.txt, a column of threshold values to be tested.
 
## Required Packages

 * BioNet - For manipulating InWeb, I thnk.
 * igraph - To manipulate graphs.
 * graph - Some more base graph functions
 * PINTS - That's the whole point of this project. Install from Github.
 * gtools - Don't actually remember what this is for, but I think one of my population simulations functions depends on it.
 * HighSpeedStats - Has a fast implementation of Fisher's exact test for large numbers.
 
## Methods

We'll use the method done in Test_Run.Rmd to test subnet-detection at each chosen threshold level. 

First, we construct the PPI network from Inweb 2. We take a random walk on the graph to choose a connected subgraph as our disease genes. We put these through our de novo mutation simulator to simulate GWAS results for each gene, mutating the disease genes at an elevated rate for patients. These gene scores are projected onto the PPI network, and we then run the subnetwork search. 

This will be run several times for each threshold value. 

We will measure performance by taking the following statistics for each threshold:

* Sensitivity - percent of true genes that are detected.
* Specificity - percent of detected negatives that are true negatives.
* False Discovery Rate - Type 1 errors, so percent of detected positives that are false discoveries
* Edge-Connectivity - The minimum number of edges that need to be removed in order to disconnect the graph (This might not be a good measure of connectivity)
* Average Degree - Average degree of each gene within the subnetwork (ignoring edges to non-detected genes)
* percent of signal (weighted by signal) (how do we do this? what does % of signal mean?)

## Threshold values

We'll use as a baseline the Bonferroni-corrected threshold for $\alpha = 0.05$, which is $\alpha_B = 5 \times 10^{-6}$. From there, we'll vary $ln(\alpha_B)$ in increments of $0.5$, up to a difference of $\pm 10$. For each threshold value, we'll run 50 trials... or I guess we could do way more if I put it onto the clusters. We'll ask Chris and see how he feels. 

For the remaining parameters, we'll use 10 true disease genes, case cohort size of 100, and 

## Experimental Setup

We've already loaded all the code for the de novo simulator, now we need to run the setup for PINTS. 

```{r}
PPINetPath <- system.file("extdata", "InWeb3_HC_PPI_comp0.net", package="PINTS")
PPIAnnotPath <- system.file("extdata", "InWeb3_HC_PPI_comp0_geneAnnotation.txt", package="PINTS")
PPI <- loadPPINetwork(PPINetPath, PPIAnnotPath)
network <- PPI$g #our network file
nodeAnnot <- PPI$nodeAnnot #data frame of node annotations

geneScorePath <- system.file("extdata", "InWeb3_HC_PPI_Evolution_pvals.txt", package="PINTS")
nodeWeightTable <- read.table(geneScorePath, head=T, stringsAsFactors=F)
#gene expression data
geneExpressionPath <- system.file("extdata", "Binary_Pref_Gene_Exp_Roadmap.txt", package="PINTS")
gExpData <- read.table(geneExpressionPath, head=T, stringsAsFactors=F)
#And this tells us which genes are actually expressed in the tissues of interest. 
genes <- gExpData[,"Ensemble"] 

walking <- function(network, steps, startGene){
  walk <- random_walk(network, start = startGene, steps)

  while(any(table(walk) > 1)){
      walk <- random_walk(network, start = startGene, steps)
  }
  
  return(walk)
}


```

### One Run

```{r, cache = TRUE}
set.seed(1234)
# Number of disease genes
nSubnet <- 10
# Number of patients in case group
n <- 100
# Base Threshold
thresh <- 3e-8

nGenes <- length(nodeAnnot[[3]])
startNode <- sample(1:nGenes, 1)
startGenes <- nodeAnnot[startNode, c('Ensemble')]

subnet <- walking(network, nSubnet, startGenes)
print(subnet)

candidate_genes <- as.data.frame(attributes(subnet)$names)
colnames(candidate_genes) <- "Ensembl"

# Double-check this portion here. Why are these frequencies uniformly distributed?
candidate_genes$freq <- runif(nrow(candidate_genes))

results <- data.frame(gene = gene_list$Ensembl, pvals = rep(1, nrow(gene_list)))

population <- Gen_pop(n, 1, 0.38)[1:n,]
population <- Initiate_population(population, gene_list$Ensembl)
population <- Cohort_mut(population,
                 gene_list$Ensembl,
                 gene_list$freq,
                 candidate_genes$Ensembl,
                 candidate_genes$freq)
cases <- colSums(population)
    
for(q in 1:nrow(gene_list)){
    results$pvals[q] <- big_fish(gene_list[q,1], cases, control_agg)
}

for(i in 1:nrow(nodeWeightTable)) {
  nodeWeightTable[i,"pvalues"] <- results[i,"pvals"]
}

#Our simulated disease network with prepicked subnet. 
diseaseNetwork <- buildDiseaseNetwork(network, nodeWeightTable, nodeAnnot, nodeNameBy ="Ensemble", nodeSelected=genes)

set.seed(1234)
nNull <- 100 #the number of null top subnetwork  
nullDiseaseNetwork <- randDiseaseNetwork(diseaseNetwork, nPermute=nNull)
print(nullDiseaseNetwork[1:10,1:12])

result <- runDiseaseSubnetSearch(diseaseNetwork, nodeAnnot, sigThres= thresh, nullDiseaseNetwork, showResult=TRUE)
subnetNodes <- result[[1]]

subnetNodesHUGO <- nodeAnnot[ which(nodeAnnot[,"Ensemble"] %in% subnetNodes), "HUGO"]
topSubnet <- induced.subgraph(diseaseNetwork, subnetNodes)
is.connected(topSubnet)
topSubnet.layout <- layout.fruchterman.reingold(topSubnet)
plot(topSubnet, layout = topSubnet.layout, main= "The MC-associated subnetwork", vertex.color="skyblue", vertex.size= 10, vertex.label=subnetNodesHUGO, vertex.label.font=3, vertex.label.cex=0.5, edge.width=2)
```

### Results

```{r}
test.validity <- data.frame(Stat = c("Sensitivity", "Specificity", "FDR", "Edge-Con"), Value = NA)

# Compute Sensitivity - True Positive Rate (Power)
check <- rep(0, length(candidate_genes$Ensembl))
for(i in 1:length(check)){
  check[i] <- any(result[[1]] == candidate_genes$Ensembl[i])
}

test.validity[test.validity$Stat == "Sensitivity", 2] <- sum(check) / length(check)
test.validity[test.validity$Stat == "FDR", 2] <- 1-test.validity[1,2]

# Compute Specificity - True Negative Rate
true_negs <- nGenes - 2*length(candidate_genes$Ensembl) +sum(check)
test.validity[test.validity$Stat == "Specificity", 2] <- true_negs/nGenes

# Compute edge-connectivity - minimum number of edges to remove to disconnect the graph
test.validity[test.validity$Stat == "Edge-Con", 2] <- edge_connectivity(topSubnet)

kable(test.validity)
```

## Actual Experimental Script

Below is the script, not evaluated in this file, which we can submit to the clusters for this experiment.

```{r, eval = FALSE, include = TRUE}
# Include all the code in the setup to this document. 

PPINetPath <- system.file("extdata", "InWeb3_HC_PPI_comp0.net", package="PINTS")
PPIAnnotPath <- system.file("extdata", "InWeb3_HC_PPI_comp0_geneAnnotation.txt", package="PINTS")
PPI <- loadPPINetwork(PPINetPath, PPIAnnotPath)
network <- PPI$g #our network file
nodeAnnot <- PPI$nodeAnnot #data frame of node annotations
nGenes <- length(nodeAnnot[[3]])


geneScorePath <- system.file("extdata", "InWeb3_HC_PPI_Evolution_pvals.txt", package="PINTS")
nodeWeightTable <- read.table(geneScorePath, head=T, stringsAsFactors=F)
#gene expression data
geneExpressionPath <- system.file("extdata", "Binary_Pref_Gene_Exp_Roadmap.txt", package="PINTS")
gExpData <- read.table(geneExpressionPath, head=T, stringsAsFactors=F)
#And this tells us which genes are actually expressed in the tissues of interest. 
genes <- gExpData[,"Ensemble"] 

walking <- function(network, steps, startGene){
  walk <- random_walk(network, start = startGene, steps)

  while(any(table(walk) > 1)){
      walk <- random_walk(network, start = startGene, steps)
  }
  
  return(walk)
}

thresh_list <- read.table("threshold_list.txt", header = TRUE)

final <- data.frame(threshold = thresh_list, sensitivity = 0, specificity = 0, FDR = 0, connectivity = 0, connected = 0)

# Set up the disease network 
# Number of disease genes
nSubnet <- 10
# Number of patients in case group
n <- 100
# Number of trials
trials <- 50

for(i in 1:nrow(final)) {
  thresh.results <-
    data.frame(sensitivity = rep(0, trials),  specificity = 0,
    FDR = 0,
    connectivity = 0
    connected = 0)
  
  for (j in 1:trials) {
    # Testing
    startNode <- sample(1:nGenes, 1)
    startGenes <- nodeAnnot[startNode, c('Ensemble')]
    
    subnet <- walking(network, nSubnet, startGenes)
    
    candidate_genes <- as.data.frame(attributes(subnet)$names)
    colnames(candidate_genes) <- "Ensembl"
    candidate_genes$freq <- runif(nrow(candidate_genes))
    
    results <-
    data.frame(gene = gene_list$Ensembl, pvals = rep(1, nrow(gene_list)))
    
    population <- Gen_pop(n, 1, 0.38)[1:n, ]
    population <- Initiate_population(population, gene_list$Ensembl)
    population <- Cohort_mut(
      population,
      gene_list$Ensembl,
      gene_list$freq,
      candidate_genes$Ensembl,
      candidate_genes$freq
      )
    cases <- colSums(population)
    
    for (q in 1:nrow(gene_list)) {
    results$pvals[q] <- big_fish(gene_list[q, 1], cases, control_agg)
    }
    
    for (q in 1:nrow(nodeWeightTable)) {
    nodeWeightTable[q, "pvalues"] <- results[q, "pvals"]
    }
    
    #Our simulated disease network with prepicked subnet.
    diseaseNetwork <-
      buildDiseaseNetwork(
        network,
        nodeWeightTable,
        nodeAnnot,
        nodeNameBy = "Ensemble",
        nodeSelected = genes
        )
    
    nNull <- 100 #the number of null top subnetwork
    nullDiseaseNetwork <-
      randDiseaseNetwork(diseaseNetwork, nPermute = nNull)

    result <-
      runDiseaseSubnetSearch(
      diseaseNetwork,
        nodeAnnot,
        sigThres = final$threshold[i],
        nullDiseaseNetwork,
        showResult = TRUE
        )
    subnetNodes <- result[[1]]
    
    topSubnet <- induced.subgraph(diseaseNetwork, subnetNodes)
    
    # Analyzing results
    # Sensitivity
    check <- rep(0, length(candidate_genes$Ensembl))
    for(q in 1:length(check)){
      check[q] <- any(result[[1]] == candidate_genes$Ensembl[i])
    }
    
    thresh.results$sensitivity[j] <- sum(check) / length(check)
    thresh.results$FDR[j] <- 1-thresh.results$sensitivity[j]
    
    # Compute Specificity - True Negative Rate
    thresh.results$specificity[j] <- (nGenes - 2*length(candidate_genes$Ensembl) +sum(check))/nGenes
    
    # Compute edge-connectivity - minimum number of edges to remove to disconnect the graph
    thresh.results$connectivity[j] <- edge_connectivity(topSubnet)
    
    # Connected - is the graph connected at all?
    thresh.results$connected[j] <- is.connected(topSubnet)
  }
  
  final[i,2:6] <- colMeans(thresh.results, na.rm = TRUE)
}

write.table(final, "Threshold_Results.txt", sep = ",",col.names = TRUE)
```

## Results

Let's take a look at the results, see what we see. 

```{r}
final <- read.table("Threshold_Results.txt" ,header = TRUE, sep = ",")

kable(final)
```

A lot of NAs. It would be interesting to see if there's any association of the smaller thresholds with the connectivity, but we'll look at just the sensitivity and specificity right now. 

```{r}
library(ggplot2)

g <- ggplot(final[1:10,], aes(x = -log(threshold)))
g <- g + geom_smooth(aes(y = sensitivity, color = "Sensitivity"))
g <- g + geom_smooth(aes(y = (specificity - .998)*1000-.2, color = "Specificity"), se = FALSE)
g <- g + scale_y_continuous(sec.axis = sec_axis(~./1000 + .998, name = "Specificity"))
g <- g + ggtitle("PINTS Sensitivity wrt threshold") + ylab("Sensitivity")
g
```

A confidence interval is only discplayed for sensitivity, since the specificity ranges over such a small interval that the confidence interval doesn't really tell us anything meaningful. Either way, the two curves are basically scaled versions of each other. That's something we've learned.

There's no optimal threshold though. I ran a few more experiments with specific thresholds, this time varying the number of cases that we have to see if different thresholds require different sample sizes for the same power. The chosen thresholds were 3e-6, 4e-7, and 9e-8, chosen because these thresholds had high sensitivities in the prior experiment. This experiment only had 10 trials per parameter set. 

```{r}
final1 <- read.table("pop_Results_3e6.txt", header = TRUE, sep = ",")
final2 <- read.table("pop_Results_4e7.txt", header = TRUE, sep = ",")
final3 <- read.table("pop_Results_9e8.txt", header = TRUE, sep = ",")

final1$threshold <- 3e-6
final2$threshold <- 4e-7
final3$threshold <- 9e-8

case_final <- rbind(final1, final2, final3)
case_final$threshold <- as.factor(case_final$threshold)

g2 <- ggplot(case_final, aes(x = case))
g2 <- g2 + geom_line(aes(y = sensitivity, color = threshold))
g2 <- g2 + ggtitle("PINTS Sensitivity wrt sample size, threshold") + ylab("Sensitivity")
g2
```

